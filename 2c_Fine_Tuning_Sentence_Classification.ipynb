{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJR6t_gCQe_x"
      },
      "source": [
        "# Fine-Tuning a Transformer Model for Sentence Classification\n",
        "\n",
        "In this notebook, we’ll fine-tune a pre-trained Transformer model for a sentence classification task. We’ll use the Hugging Face Transformers library along with the Datasets library to handle data loading and preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table of Contents\n",
        "\n",
        "- [1. Introduction](#1-introduction)\n",
        "- [2. Setup and Installation](#2-setup-and-installation)\n",
        "- [3. Set Random Seed for Reproducibility](#3-set-random-seed-for-reproducibility)\n",
        "- [4. Load and Explore the Dataset](#4-load-and-explore-the-dataset)\n",
        "- [5. Prepare a Small Subset of the Dataset](#5-prepare-a-small-subset-of-the-dataset)\n",
        "- [6. Preprocess and Tokenize the Dataset](#6-preprocess-and-tokenize-the-dataset)\n",
        "- [7. Evaluate the Pre-trained Model (Baseline)](#7-evaluate-the-pre-trained-model-baseline)\n",
        "- [8. Fine-Tune the Model](#8-fine-tune-the-model)\n",
        "- [9. Evaluate the Fine-Tuned Model](#9-evaluate-the-fine-tuned-model)\n",
        "- [10. Visualize Results](#10-visualize-results)\n",
        "- [11. Conclusion](#11-conclusion)\n",
        "- [12. Additional Resources](#12-additional-resources)"
      ],
      "metadata": {
        "id": "t7nHrp1X0tKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is BERT?**\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained language model released by Google. It can be fine-tuned for a variety of NLP tasks such as classification, entity recognition, and question answering. By adding an untrained layer on top of BERT and training it on your specific task, you can leverage its deep understanding of language to achieve excellent results.\n",
        "\n",
        "**Why Fine-Tune BERT Instead of Building Your Own Model?**\n",
        "\n",
        "* Easy Training: BERT’s pre-trained weights contain extensive language knowledge,\n",
        "so fine-tuning requires significantly less time—often just 2-4 epochs—compared to training a model from scratch, which can take hundreds of GPU hours.\n",
        "\n",
        "* Less Data: Fine-tuning BERT can be done with much smaller datasets, making it feasible even when large amounts of labeled data are not available.\n",
        "\n",
        "* High Performance: Simply adding a fully connected layer on top of BERT and fine-tuning it has been shown to achieve state-of-the-art results across various tasks without the need for complex, task-specific architectures.\n",
        "\n",
        "**A Shift in NLP**\n",
        "\n",
        "This approach mirrors a shift previously seen in computer vision, where pre-trained models are commonly fine-tuned for specific tasks, saving time and resources. The emergence of models like BERT represents a similar transformation in NLP, making powerful language models more accessible and efficient to use.\n",
        "\n",
        "***Let’s get started!***"
      ],
      "metadata": {
        "id": "TeYInyNs0ufB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Installation\n"
      ],
      "metadata": {
        "id": "2_zWj-OSpRAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install --quiet --upgrade transformers datasets evaluate"
      ],
      "metadata": {
        "id": "ezLSWsGXpPsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from evaluate import load as load_metric\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "rlGCX_UJpVyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "eiZPyHoS1dNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load Dataset\n",
        "\n",
        "We’ll use the SST-2 dataset from the GLUE benchmark, which is a binary sentiment classification task."
      ],
      "metadata": {
        "id": "VfTEchkf1mvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SST-2 dataset\n",
        "dataset = load_dataset('glue', 'sst2')\n",
        "\n",
        "# Explore the dataset structure\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "u9csrsI2pdbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a sample from the training set\n",
        "print(\"Training sample:\")\n",
        "print(dataset['train'][0])\n",
        "\n",
        "# View a sample from the validation set\n",
        "print(\"\\nValidation sample:\")\n",
        "print(dataset['validation'][0])"
      ],
      "metadata": {
        "id": "Zl_buVr113xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prepare a Small Subset of the Dataset\n"
      ],
      "metadata": {
        "id": "HQdgoxLl16aS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a small subset for training and evaluation\n",
        "small_train_dataset = dataset['train'].shuffle(seed=seed).select(range(500))  # 500 samples for training\n",
        "small_eval_dataset = dataset['validation'].shuffle(seed=seed).select(range(100))  # 100 samples for evaluation\n",
        "\n",
        "# Create a DatasetDict\n",
        "small_dataset = DatasetDict({\n",
        "    'train': small_train_dataset,\n",
        "    'validation': small_eval_dataset\n",
        "})\n"
      ],
      "metadata": {
        "id": "noA1Itvztxsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Preprocess and Tokenize the Dataset\n"
      ],
      "metadata": {
        "id": "dcRZyyFp2FfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose a Pre-trained Model and Tokenizer\n",
        "\n",
        "Let’s load a pre-trained BERT model! There are several options available, and we’ll use distilbert-base-uncased, which is a lighter and faster version of BERT. The term “uncased” means the model was trained on lowercase text only, and “distilbert” refers to a distilled version of BERT that is smaller and more efficient while retaining much of its performance.\n",
        "\n",
        "\n",
        "\n",
        "<img src='http://jalammar.github.io/images/bert-classifier.png' width=700px>\n",
        "\n",
        "source: [The Illustrated BERT](http://jalammar.github.io/illustrated-bert/)\n",
        "\n",
        "We’ll use the distilbert-base-uncased model for its balance between performance and computational efficiency."
      ],
      "metadata": {
        "id": "h7AFJHE82Ngy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "9j22SEYvrpvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sentence'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = small_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "jRCF3oQI2Ddp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "id": "1FbwpUSCr1kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluate the Pre-trained Model (Baseline)\n",
        "\n",
        "Before fine-tuning, let’s evaluate the pre-trained model to establish a baseline performance.\n"
      ],
      "metadata": {
        "id": "uiAU9Xn_2YX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "mU7yPt9huUuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric('accuracy')"
      ],
      "metadata": {
        "id": "LxxE-4fer-R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = metric.compute(predictions=predictions, references=labels)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "rGsmfAtxsA8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=64,\n",
        "    do_train=False,\n",
        "    do_eval=True,\n",
        "    eval_strategy='no',\n",
        "    logging_steps=10\n",
        ")"
      ],
      "metadata": {
        "id": "GHhJm1JusB-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "Q1DCvS_jsCBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = tokenized_datasets['validation']"
      ],
      "metadata": {
        "id": "tw-BlSkhr4sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the pre-trained model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Baseline accuracy of the pre-trained model: {eval_results['eval_accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "1iCS8HAUtv3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate predictions\n",
        "predictions = trainer.predict(tokenized_datasets['validation'])\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(labels, preds, zero_division=0))"
      ],
      "metadata": {
        "id": "IkEXweM_61FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Fine-Tune the Model\n",
        "Now we’ll fine-tune the pre-trained model on our small training dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "jbaMXEwG28LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update training arguments for fine-tuning\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',   # Evaluation strategy set to 'epoch'\n",
        "    save_strategy='epoch',   # Save strategy matches eval_strategy\n",
        "    num_train_epochs=1,      # Reduced to 1 epoch for quick training\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    logging_steps=10,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_accuracy',\n",
        "    greater_is_better=True\n",
        ")"
      ],
      "metadata": {
        "id": "GvsykRdZ3Fi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-initialize the trainer with training dataset\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "9x3vr1z43HZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "iSy3LGsc3JZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluate the Fine-Tuned Model\n"
      ],
      "metadata": {
        "id": "u5fBZciG3LyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Accuracy of the fine-tuned model: {eval_results['eval_accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "VcBezn_TsCEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Analysis"
      ],
      "metadata": {
        "id": "svCP4wJv3Rxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = trainer.predict(tokenized_datasets['validation'])\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "labels = predictions.label_ids"
      ],
      "metadata": {
        "id": "OxBoFTsnuorg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print classification report\n",
        "print(classification_report(labels, preds, zero_division=0))"
      ],
      "metadata": {
        "id": "DnUAjnao3Wrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(labels, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "656XYzqP3Y27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Challenge: Improving the Model\n",
        "\n",
        "#### **TODO**: Think of Ways to Improve the Results\n",
        "\n",
        "**Your Task:**\n",
        "*\t**Objective**: Explore and implement strategies to improve the model’s performance as much as possible.\n",
        "\n",
        "\n",
        "##### Consider the Following Approaches:\n",
        "*\t**Hyperparameter Tuning**: Experiment with different learning rates, batch sizes, and number of epochs.\n",
        "*\tData Augmentation: Use techniques to expand or enhance the training dataset.\n",
        "*\tUsing a Larger Dataset: Increase the number of samples in the training set.\n",
        "*\tTry Different Pre-trained Models: Use models like bert-base-uncased or roberta-base.\n",
        "*\tAdjust the Tokenization Parameters: Modify max_length, padding, and truncation settings.\n",
        "*\tLayer Freezing/Unfreezing: Experiment with freezing certain layers of the model during training.\n",
        "*\tRegularization Techniques: Apply techniques like dropout or weight decay.\n",
        "*\tImplement and Document:\n",
        "*\tCode Changes: Apply the changes in the code cells.\n",
        "*\tObservations: Note the impact of each change on the model’s performance.\n",
        "*\tAnalysis: Discuss why certain changes improved or did not improve the results."
      ],
      "metadata": {
        "id": "WnjfdtkXDweg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Conclusion\n",
        "\n",
        "In this notebook, we:\n",
        "*\tUsed a small subset of the SST-2 dataset to reduce training time.\n",
        "*\tEvaluated the pre-trained BERT model to establish a baseline.\n",
        "*\tFine-tuned the model quickly (1 epoch).\n",
        "*\tObserved the improvement in accuracy after fine-tuning.\n",
        "*\tVisualized the results using a confusion matrix and classification report.\n",
        "\n",
        "Key Takeaways:\n",
        "*\tEfficient Training: By reducing the dataset size and epochs, we can fine-tune models quickly.\n",
        "*\tBaseline Comparison: Evaluating before and after fine-tuning highlights the impact of training.\n",
        "*\tSimplified Preprocessing: Utilizing the transformers library simplifies data preprocessing."
      ],
      "metadata": {
        "id": "QMo_2h5s3hkl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHh9k1SBD1rK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}